{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2039619",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Inference Pipeline: Production-Ready Predictions\n",
    "\n",
    "This notebook demonstrates the complete inference pipeline for making predictions with trained RL agents.\n",
    "\n",
    "**Topics covered:**\n",
    "- Single observation inference\n",
    "- Batch inference\n",
    "- Risk management\n",
    "- Performance monitoring\n",
    "- Production deployment patterns\n",
    "\n",
    "**Time required:** ~20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2011436",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc346d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Project root: e:\\Derivative_Hedging_RL\n",
      "âœ“ Python path configured\n"
     ]
    }
   ],
   "source": [
    "# Add project root to Python path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the project root (parent of notebooks directory)\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"âœ“ Project root: {project_root}\")\n",
    "print(f\"âœ“ Python path configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3eebcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports successful!\n",
      "âœ“ Pipeline module reloaded with latest changes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "# Inference pipeline (reload to get latest changes)\n",
    "from src.inference import pipeline as pipeline_module\n",
    "importlib.reload(pipeline_module)\n",
    "from src.inference.pipeline import InferencePipeline\n",
    "from src.inference.data_loader import DataLoader\n",
    "from src.inference.preprocessor import DataPreprocessor\n",
    "from src.inference.postprocessor import PostProcessor\n",
    "\n",
    "# For comparison\n",
    "from src.agents.trainer import AgentTrainer\n",
    "from src.agents.config import get_config, ENV_CONFIGS\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"âœ“ Imports successful!\")\n",
    "print(\"âœ“ Pipeline module reloaded with latest changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c59b6",
   "metadata": {},
   "source": [
    "## 2. Train a Model (or Load Existing)\n",
    "\n",
    "For this demo, we'll train a quick model. In production, you'd load a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a60aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Using existing model: models\\notebook_inference\\ppo_quick.zip\n"
     ]
    }
   ],
   "source": [
    "# Check if we have a trained model\n",
    "model_path = Path(\"models/notebook_inference/ppo_quick.zip\")\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(\"No existing model found. Training a new one...\")\n",
    "    print(\"This will take ~5 minutes\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Train a model\n",
    "    trainer = AgentTrainer(\n",
    "        agent_type=\"PPO\",\n",
    "        env_config=ENV_CONFIGS[\"medium\"],\n",
    "        output_dir=\"models/notebook_inference\",\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    agent = trainer.quick_train(\n",
    "        agent_config=get_config(\"PPO\", \"fast_learning\"),\n",
    "        total_timesteps=50000,\n",
    "    )\n",
    "    \n",
    "    # Save it\n",
    "    agent.save(\"models/notebook_inference/ppo_quick\")\n",
    "    print(\"\\nâœ“ Model trained and saved!\")\n",
    "else:\n",
    "    print(f\"âœ“ Using existing model: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a0a39",
   "metadata": {},
   "source": [
    "## 3. Initialize Inference Pipeline\n",
    "\n",
    "The InferencePipeline class handles the entire workflow:\n",
    "**Data â†’ Load â†’ Clean â†’ Pre-Process â†’ Inference â†’ Post-Process**\n",
    "\n",
    "**Important:** The pipeline needs to know the environment configuration that was used during training. The observation space must match between training and inference. \n",
    "\n",
    "- Models trained with `quick_train` on \"medium\" config: use `env_config=ENV_CONFIGS[\"medium\"]`\n",
    "- Models trained with `train_with_curriculum`: use `env_config=ENV_CONFIGS[\"hard\"]` (final stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66257e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Inference Pipeline Initialized\n",
      "================================================================================\n",
      "Model Type: PPO\n",
      "Model Path: models\\notebook_inference\\ppo_quick.zip\n",
      "Environment Config: medium (n_steps=100)\n",
      "Risk Limits Enabled: True\n",
      "Max Hedge Ratio: 2.0\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\gymnasium\\spaces\\box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "e:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\gymnasium\\spaces\\box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "e:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline\n",
    "# Note: Model was trained with 'medium' config (n_steps=100)\n",
    "# Must pass matching env_config for correct observation space\n",
    "pipeline = InferencePipeline(\n",
    "    model_path=\"models/notebook_inference/ppo_quick.zip\",\n",
    "    model_type=\"PPO\",\n",
    "    env_config=ENV_CONFIGS[\"medium\"],  # Match training config\n",
    "    apply_risk_limits=True,\n",
    "    max_hedge_ratio=2.0,\n",
    "    log_predictions=True,\n",
    ")\n",
    "\n",
    "# Get model info\n",
    "model_info = pipeline.get_model_info()\n",
    "\n",
    "print(\"Inference Pipeline Initialized\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Model Type: {model_info['model_type']}\")\n",
    "print(f\"Model Path: {model_info['model_path']}\")\n",
    "print(f\"Environment Config: medium (n_steps=100)\")\n",
    "print(f\"Risk Limits Enabled: {model_info['risk_limits_enabled']}\")\n",
    "print(f\"Max Hedge Ratio: {model_info['max_hedge_ratio']}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70546066",
   "metadata": {},
   "source": [
    "## 4. Single Observation Inference\n",
    "\n",
    "Let's make a prediction for a single market condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4932e75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to calculate Greeks: type object 'BlackScholesModel' has no attribute 'delta'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SINGLE PREDICTION RESULT\n",
      "================================================================================\n",
      "\n",
      "Market Conditions:\n",
      "  Spot Price: $(11,)\n",
      "  Moneyness: 1.05 (in-the-money)\n",
      "  Time to Expiration: 3 months\n",
      "  Volatility: 25%\n",
      "\n",
      "Prediction:\n",
      "  Status: success\n",
      "  Target Hedge Ratio: -0.6364\n",
      "  Shares to Trade: -1.1364\n",
      "  Trade Value: $-119.32\n",
      "  Confidence: 100.00%\n",
      "  Inference Time: 2.44 ms\n",
      "\n",
      "ðŸ“Š Action: DECREASE hedge position\n"
     ]
    }
   ],
   "source": [
    "# Market scenario: Slightly in-the-money call option\n",
    "result = pipeline.predict_single(\n",
    "    spot_price=105.0,        # Current stock price\n",
    "    strike=100.0,            # Strike price\n",
    "    time_to_maturity=0.25,   # 3 months to expiration\n",
    "    risk_free_rate=0.05,     # 5% risk-free rate\n",
    "    volatility=0.25,         # 25% implied volatility\n",
    "    option_type=\"call\",\n",
    "    current_hedge=0.5,       # Currently 50% hedged\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SINGLE PREDICTION RESULT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nMarket Conditions:\")\n",
    "print(f\"  Spot Price: ${result['metadata']['features_shape']}\")\n",
    "print(f\"  Moneyness: {105/100:.2f} (in-the-money)\")\n",
    "print(f\"  Time to Expiration: 3 months\")\n",
    "print(f\"  Volatility: 25%\")\n",
    "\n",
    "print(f\"\\nPrediction:\")\n",
    "print(f\"  Status: {result['status']}\")\n",
    "print(f\"  Target Hedge Ratio: {result['prediction']['target_hedge_ratio']:.4f}\")\n",
    "print(f\"  Shares to Trade: {result['prediction']['shares_to_trade']:.4f}\")\n",
    "print(f\"  Trade Value: ${result['prediction']['trade_value']:.2f}\")\n",
    "print(f\"  Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"  Inference Time: {result['metadata']['inference_time_ms']:.2f} ms\")\n",
    "\n",
    "# Interpret\n",
    "current_hedge = 0.5\n",
    "target_hedge = result['prediction']['target_hedge_ratio']\n",
    "action = \"INCREASE\" if target_hedge > current_hedge else \"DECREASE\"\n",
    "print(f\"\\nðŸ“Š Action: {action} hedge position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e6d5e",
   "metadata": {},
   "source": [
    "## 5. Batch Inference: Multiple Scenarios\n",
    "\n",
    "Let's create a batch of different market scenarios and run inference on all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ad337a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created 200 diverse test scenarios\n",
      "\n",
      "Scenario Distribution:\n",
      "scenario_type\n",
      "standard           80\n",
      "out_of_money       40\n",
      "in_the_money       40\n",
      "high_volatility    20\n",
      "near_expiration    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Option Type Distribution:\n",
      "option_type\n",
      "call    105\n",
      "put      95\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 scenarios:\n",
      "   spot_price  strike  time_to_maturity  volatility option_type scenario_type  \\\n",
      "0   98.745401   100.0          0.445241    0.216778         put      standard   \n",
      "1  104.507143   100.0          0.349319    0.243231         put      standard   \n",
      "2  102.319939   100.0          0.232359    0.243353        call      standard   \n",
      "3  100.986585   100.0          0.125423    0.233577         put      standard   \n",
      "4   96.560186   100.0          0.224393    0.189029        call      standard   \n",
      "\n",
      "   moneyness  \n",
      "0   0.987454  \n",
      "1   1.045071  \n",
      "2   1.023199  \n",
      "3   1.009866  \n",
      "4   0.965602  \n"
     ]
    }
   ],
   "source": [
    "# Create diverse test scenarios with different market conditions\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Generate diverse scenarios\n",
    "scenarios = []\n",
    "\n",
    "# 1. Standard scenarios (40%)\n",
    "n_standard = int(n_samples * 0.4)\n",
    "scenarios.append(pd.DataFrame({\n",
    "    'spot_price': np.random.uniform(95, 105, n_standard),\n",
    "    'strike': 100.0,\n",
    "    'time_to_maturity': np.random.uniform(0.1, 0.5, n_standard),\n",
    "    'risk_free_rate': 0.05,\n",
    "    'volatility': np.random.uniform(0.18, 0.28, n_standard),\n",
    "    'option_type': np.random.choice(['call', 'put'], n_standard),\n",
    "    'current_hedge': np.random.uniform(0.3, 0.7, n_standard),\n",
    "    'scenario_type': 'standard',\n",
    "}))\n",
    "\n",
    "# 2. Out-of-the-money scenarios (20%)\n",
    "n_otm = int(n_samples * 0.2)\n",
    "otm_spots = np.concatenate([\n",
    "    np.random.uniform(85, 95, n_otm//2),  # OTM calls\n",
    "    np.random.uniform(105, 115, n_otm//2),  # OTM puts\n",
    "])\n",
    "otm_types = ['call'] * (n_otm//2) + ['put'] * (n_otm//2)\n",
    "scenarios.append(pd.DataFrame({\n",
    "    'spot_price': otm_spots,\n",
    "    'strike': 100.0,\n",
    "    'time_to_maturity': np.random.uniform(0.1, 0.5, n_otm),\n",
    "    'risk_free_rate': 0.05,\n",
    "    'volatility': np.random.uniform(0.20, 0.30, n_otm),\n",
    "    'option_type': otm_types,\n",
    "    'current_hedge': np.random.uniform(0.1, 0.4, n_otm),\n",
    "    'scenario_type': 'out_of_money',\n",
    "}))\n",
    "\n",
    "# 3. In-the-money scenarios (20%)\n",
    "n_itm = int(n_samples * 0.2)\n",
    "itm_spots = np.concatenate([\n",
    "    np.random.uniform(105, 115, n_itm//2),  # ITM calls\n",
    "    np.random.uniform(85, 95, n_itm//2),  # ITM puts\n",
    "])\n",
    "itm_types = ['call'] * (n_itm//2) + ['put'] * (n_itm//2)\n",
    "scenarios.append(pd.DataFrame({\n",
    "    'spot_price': itm_spots,\n",
    "    'strike': 100.0,\n",
    "    'time_to_maturity': np.random.uniform(0.1, 0.5, n_itm),\n",
    "    'risk_free_rate': 0.05,\n",
    "    'volatility': np.random.uniform(0.20, 0.30, n_itm),\n",
    "    'option_type': itm_types,\n",
    "    'current_hedge': np.random.uniform(0.5, 0.9, n_itm),\n",
    "    'scenario_type': 'in_the_money',\n",
    "}))\n",
    "\n",
    "# 4. High volatility regime (10%)\n",
    "n_high_vol = int(n_samples * 0.1)\n",
    "scenarios.append(pd.DataFrame({\n",
    "    'spot_price': np.random.uniform(90, 110, n_high_vol),\n",
    "    'strike': 100.0,\n",
    "    'time_to_maturity': np.random.uniform(0.1, 0.5, n_high_vol),\n",
    "    'risk_free_rate': 0.05,\n",
    "    'volatility': np.random.uniform(0.35, 0.50, n_high_vol),\n",
    "    'option_type': np.random.choice(['call', 'put'], n_high_vol),\n",
    "    'current_hedge': np.random.uniform(0.3, 0.7, n_high_vol),\n",
    "    'scenario_type': 'high_volatility',\n",
    "}))\n",
    "\n",
    "# 5. Near expiration (10%)\n",
    "n_near_exp = n_samples - n_standard - n_otm - n_itm - n_high_vol\n",
    "scenarios.append(pd.DataFrame({\n",
    "    'spot_price': np.random.uniform(95, 105, n_near_exp),\n",
    "    'strike': 100.0,\n",
    "    'time_to_maturity': np.random.uniform(0.01, 0.08, n_near_exp),  # 3-20 days\n",
    "    'risk_free_rate': 0.05,\n",
    "    'volatility': np.random.uniform(0.20, 0.35, n_near_exp),\n",
    "    'option_type': np.random.choice(['call', 'put'], n_near_exp),\n",
    "    'current_hedge': np.random.uniform(0.3, 0.7, n_near_exp),\n",
    "    'scenario_type': 'near_expiration',\n",
    "}))\n",
    "\n",
    "# Combine all scenarios\n",
    "test_data = pd.concat(scenarios, ignore_index=True)\n",
    "\n",
    "# Add moneyness for analysis\n",
    "test_data['moneyness'] = test_data['spot_price'] / test_data['strike']\n",
    "\n",
    "# Save to CSV\n",
    "test_data.to_csv(\"data/test_scenarios.csv\", index=False)\n",
    "\n",
    "print(f\"âœ“ Created {len(test_data)} diverse test scenarios\")\n",
    "print(\"\\nScenario Distribution:\")\n",
    "print(test_data['scenario_type'].value_counts())\n",
    "print(\"\\nOption Type Distribution:\")\n",
    "print(test_data['option_type'].value_counts())\n",
    "print(\"\\nFirst 5 scenarios:\")\n",
    "print(test_data[['spot_price', 'strike', 'time_to_maturity', 'volatility', \n",
    "                  'option_type', 'scenario_type', 'moneyness']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ccddb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "âœ“ Modules reloaded with latest fixes\n",
      "âœ“ Pipeline recreated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\gymnasium\\spaces\\box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "e:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\gymnasium\\spaces\\box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "e:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reload modules to get the latest fixes\n",
    "import importlib\n",
    "from src.inference import pipeline as pipeline_module\n",
    "from src.inference import preprocessor as preprocessor_module\n",
    "\n",
    "importlib.reload(preprocessor_module)\n",
    "importlib.reload(pipeline_module)\n",
    "\n",
    "from src.inference.pipeline import InferencePipeline\n",
    "\n",
    "# Recreate pipeline with reloaded modules\n",
    "pipeline = InferencePipeline(\n",
    "    model_path=\"models/notebook_inference/ppo_quick.zip\",\n",
    "    model_type=\"PPO\",\n",
    "    env_config=ENV_CONFIGS[\"medium\"],\n",
    "    apply_risk_limits=True,\n",
    "    max_hedge_ratio=2.0,\n",
    "    log_predictions=True,\n",
    ")\n",
    "\n",
    "print(\"âœ“ Modules reloaded with latest fixes\")\n",
    "print(\"âœ“ Pipeline recreated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaca727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running batch inference...\n",
      "================================================================================\n",
      "\n",
      "âœ“ Batch inference complete!\n",
      "  Total time: 0.11 seconds\n",
      "  Throughput: 1878.0 predictions/second\n",
      "  Average time per prediction: 0.53 ms\n",
      "  Results saved to: results/batch_predictions.csv\n",
      "\n",
      "Performance Summary:\n",
      "  Total Scenarios: 200\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPerformance Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Total Scenarios: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Successful Predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstatus\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;250m \u001b[39m==\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m'\u001b[39m).sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Average Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_df[\u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Min Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_df[\u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Derivative_Hedging_RL\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'status'"
     ]
    }
   ],
   "source": [
    "# Run batch inference with performance tracking\n",
    "print(\"\\nRunning batch inference...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_df = pipeline.predict_batch(\n",
    "    data=\"data/test_scenarios.csv\",\n",
    "    deterministic=True,\n",
    "    save_results=\"results/batch_predictions.csv\",\n",
    ")\n",
    "\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Calculate Black-Scholes Delta for comparison\n",
    "from scipy.stats import norm\n",
    "\n",
    "def black_scholes_delta(S, K, T, r, sigma, option_type='call'):\n",
    "    \"\"\"Calculate Black-Scholes delta\"\"\"\n",
    "    if T <= 0:\n",
    "        # At expiration\n",
    "        if option_type == 'call':\n",
    "            return 1.0 if S > K else 0.0\n",
    "        else:\n",
    "            return -1.0 if S < K else 0.0\n",
    "    \n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    \n",
    "    if option_type == 'call':\n",
    "        return norm.cdf(d1)\n",
    "    else:\n",
    "        return norm.cdf(d1) - 1.0\n",
    "\n",
    "# Add Black-Scholes delta as benchmark\n",
    "results_df['bs_delta'] = results_df.apply(\n",
    "    lambda row: black_scholes_delta(\n",
    "        row['spot_price'], row['strike'], row['time_to_maturity'],\n",
    "        row['risk_free_rate'], row['volatility'], row['option_type']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Calculate deviation from Black-Scholes\n",
    "results_df['delta_deviation'] = results_df['target_hedge_ratio'] - results_df['bs_delta']\n",
    "results_df['abs_delta_deviation'] = np.abs(results_df['delta_deviation'])\n",
    "\n",
    "print(f\"\\nâœ“ Batch inference complete!\")\n",
    "print(f\"  Total time: {inference_time:.2f} seconds\")\n",
    "print(f\"  Throughput: {len(results_df)/inference_time:.1f} predictions/second\")\n",
    "print(f\"  Average time per prediction: {inference_time/len(results_df)*1000:.2f} ms\")\n",
    "print(f\"  Results saved to: results/batch_predictions.csv\")\n",
    "\n",
    "# Performance breakdown\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"  Total Scenarios: {len(results_df)}\")\n",
    "print(f\"  Average Confidence: {results_df['confidence'].mean():.2%}\")\n",
    "print(f\"  Min Confidence: {results_df['confidence'].min():.2%}\")\n",
    "print(f\"  Max Confidence: {results_df['confidence'].max():.2%}\")\n",
    "\n",
    "# Benchmark comparison\n",
    "print(f\"\\nBenchmark Comparison (vs Black-Scholes Delta):\")\n",
    "print(f\"  Mean Absolute Deviation: {results_df['abs_delta_deviation'].mean():.4f}\")\n",
    "print(f\"  Median Absolute Deviation: {results_df['abs_delta_deviation'].median():.4f}\")\n",
    "print(f\"  Max Absolute Deviation: {results_df['abs_delta_deviation'].max():.4f}\")\n",
    "print(f\"  Correlation with BS Delta: {results_df['target_hedge_ratio'].corr(results_df['bs_delta']):.4f}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE RESULTS (First 10)\")\n",
    "print(\"=\" * 80)\n",
    "display_cols = ['spot_price', 'option_type', 'scenario_type', 'time_to_maturity', \n",
    "                'volatility', 'target_hedge_ratio', 'bs_delta', 'delta_deviation', 'confidence']\n",
    "print(results_df[display_cols].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b6ee7b",
   "metadata": {},
   "source": [
    "### 5.1 Scenario-Specific Analysis\n",
    "\n",
    "Let's analyze how the model performs across different scenario types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by scenario type and calculate metrics\n",
    "scenario_analysis = results_df.groupby('scenario_type').agg({\n",
    "    'target_hedge_ratio': ['mean', 'std', 'min', 'max'],\n",
    "    'bs_delta': ['mean'],\n",
    "    'abs_delta_deviation': ['mean', 'max'],\n",
    "    'confidence': ['mean', 'min'],\n",
    "    'trade_value': lambda x: np.abs(x).mean(),\n",
    "}).round(4)\n",
    "\n",
    "scenario_analysis.columns = ['_'.join(col).strip() for col in scenario_analysis.columns.values]\n",
    "scenario_analysis = scenario_analysis.rename(columns={\n",
    "    'target_hedge_ratio_mean': 'Avg_Hedge_Ratio',\n",
    "    'target_hedge_ratio_std': 'Std_Hedge_Ratio',\n",
    "    'target_hedge_ratio_min': 'Min_Hedge_Ratio',\n",
    "    'target_hedge_ratio_max': 'Max_Hedge_Ratio',\n",
    "    'bs_delta_mean': 'Avg_BS_Delta',\n",
    "    'abs_delta_deviation_mean': 'Avg_Deviation',\n",
    "    'abs_delta_deviation_max': 'Max_Deviation',\n",
    "    'confidence_mean': 'Avg_Confidence',\n",
    "    'confidence_min': 'Min_Confidence',\n",
    "    'trade_value_<lambda>': 'Avg_Trade_Size',\n",
    "})\n",
    "\n",
    "print(\"Performance by Scenario Type\")\n",
    "print(\"=\" * 100)\n",
    "print(scenario_analysis.to_string())\n",
    "\n",
    "# Visualize scenario comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Average hedge ratio by scenario\n",
    "scenario_summary = results_df.groupby('scenario_type')['target_hedge_ratio'].mean().sort_values()\n",
    "axes[0, 0].barh(scenario_summary.index, scenario_summary.values, color='steelblue')\n",
    "axes[0, 0].set_xlabel('Average Hedge Ratio')\n",
    "axes[0, 0].set_title('Average Hedge Ratio by Scenario Type')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Deviation from Black-Scholes by scenario\n",
    "scenario_dev = results_df.groupby('scenario_type')['abs_delta_deviation'].mean().sort_values()\n",
    "axes[0, 1].barh(scenario_dev.index, scenario_dev.values, color='coral')\n",
    "axes[0, 1].set_xlabel('Mean Absolute Deviation from BS Delta')\n",
    "axes[0, 1].set_title('Deviation from Black-Scholes by Scenario')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Confidence by scenario type\n",
    "scenario_conf = results_df.groupby('scenario_type')['confidence'].mean().sort_values()\n",
    "axes[1, 0].barh(scenario_conf.index, scenario_conf.values, color='mediumseagreen')\n",
    "axes[1, 0].set_xlabel('Average Confidence')\n",
    "axes[1, 0].set_title('Model Confidence by Scenario Type')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Distribution of hedge ratios by scenario\n",
    "scenario_types = results_df['scenario_type'].unique()\n",
    "positions = np.arange(len(scenario_types))\n",
    "box_data = [results_df[results_df['scenario_type'] == st]['target_hedge_ratio'].values \n",
    "            for st in scenario_types]\n",
    "bp = axes[1, 1].boxplot(box_data, positions=positions, patch_artist=True, labels=scenario_types)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "axes[1, 1].set_ylabel('Hedge Ratio')\n",
    "axes[1, 1].set_title('Hedge Ratio Distribution by Scenario')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/scenario_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Scenario analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4ce9f",
   "metadata": {},
   "source": [
    "### 5.2 Pre-Defined Market Scenarios\n",
    "\n",
    "Test the model on specific real-world scenarios like market crashes, low volatility periods, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define real-world scenario templates\n",
    "scenario_templates = {\n",
    "    'market_crash': {\n",
    "        'name': 'Market Crash (-20%)',\n",
    "        'spot_price': 80.0,\n",
    "        'strike': 100.0,\n",
    "        'time_to_maturity': 0.25,\n",
    "        'risk_free_rate': 0.05,\n",
    "        'volatility': 0.60,  # Very high volatility\n",
    "        'option_type': 'call',\n",
    "        'current_hedge': 0.5,\n",
    "        'description': 'Sudden market drop with volatility spike'\n",
    "    },\n",
    "    'bull_run': {\n",
    "        'name': 'Strong Bull Market (+15%)',\n",
    "        'spot_price': 115.0,\n",
    "        'strike': 100.0,\n",
    "        'time_to_maturity': 0.25,\n",
    "        'risk_free_rate': 0.05,\n",
    "        'volatility': 0.18,  # Low volatility\n",
    "        'option_type': 'call',\n",
    "        'current_hedge': 0.7,\n",
    "        'description': 'Strong upward trend with low volatility'\n",
    "    },\n",
    "    'low_vol_regime': {\n",
    "        'name': 'Low Volatility Period',\n",
    "        'spot_price': 100.0,\n",
    "        'strike': 100.0,\n",
    "        'time_to_maturity': 0.50,\n",
    "        'risk_free_rate': 0.05,\n",
    "        'volatility': 0.10,  # Extremely low volatility\n",
    "        'option_type': 'call',\n",
    "        'current_hedge': 0.5,\n",
    "        'description': 'Calm markets with minimal movement'\n",
    "    },\n",
    "    'pre_earnings': {\n",
    "        'name': 'Pre-Earnings Announcement',\n",
    "        'spot_price': 102.0,\n",
    "        'strike': 100.0,\n",
    "        'time_to_maturity': 0.05,  # 2 weeks\n",
    "        'risk_free_rate': 0.05,\n",
    "        'volatility': 0.45,  # High implied vol\n",
    "        'option_type': 'call',\n",
    "        'current_hedge': 0.6,\n",
    "        'description': 'High uncertainty before major announcement'\n",
    "    },\n",
    "    'expiration_week': {\n",
    "        'name': 'Expiration Week (ATM)',\n",
    "        'spot_price': 100.0,\n",
    "        'strike': 100.0,\n",
    "        'time_to_maturity': 0.0192,  # 5 days\n",
    "        'risk_free_rate': 0.05,\n",
    "        'volatility': 0.30,\n",
    "        'option_type': 'call',\n",
    "        'current_hedge': 0.5,\n",
    "        'description': 'Close to expiration, at-the-money'\n",
    "    },\n",
    "    'deep_otm_put': {\n",
    "        'name': 'Deep OTM Protective Put',\n",
    "        'spot_price': 110.0,\n",
    "        'strike': 100.0,\n",
    "        'time_to_maturity': 0.25,\n",
    "        'risk_free_rate': 0.05,\n",
    "        'volatility': 0.25,\n",
    "        'option_type': 'put',\n",
    "        'current_hedge': 0.1,\n",
    "        'description': 'Far out-of-the-money put protection'\n",
    "    },\n",
    "}\n",
    "\n",
    "# Run predictions on all scenario templates\n",
    "print(\"Testing Pre-Defined Market Scenarios\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "template_results = []\n",
    "\n",
    "for key, scenario in scenario_templates.items():\n",
    "    result = pipeline.predict_single(\n",
    "        spot_price=scenario['spot_price'],\n",
    "        strike=scenario['strike'],\n",
    "        time_to_maturity=scenario['time_to_maturity'],\n",
    "        risk_free_rate=scenario['risk_free_rate'],\n",
    "        volatility=scenario['volatility'],\n",
    "        option_type=scenario['option_type'],\n",
    "        current_hedge=scenario['current_hedge'],\n",
    "        deterministic=True,\n",
    "    )\n",
    "    \n",
    "    # Calculate BS Delta for comparison\n",
    "    bs_delta = black_scholes_delta(\n",
    "        scenario['spot_price'], scenario['strike'], scenario['time_to_maturity'],\n",
    "        scenario['risk_free_rate'], scenario['volatility'], scenario['option_type']\n",
    "    )\n",
    "    \n",
    "    template_results.append({\n",
    "        'Scenario': scenario['name'],\n",
    "        'Description': scenario['description'],\n",
    "        'Spot': scenario['spot_price'],\n",
    "        'Strike': scenario['strike'],\n",
    "        'TTM': scenario['time_to_maturity'],\n",
    "        'Vol': scenario['volatility'],\n",
    "        'Type': scenario['option_type'],\n",
    "        'RL_Hedge': result['prediction']['target_hedge_ratio'],\n",
    "        'BS_Delta': bs_delta,\n",
    "        'Deviation': result['prediction']['target_hedge_ratio'] - bs_delta,\n",
    "        'Confidence': result['confidence'],\n",
    "        'Action': result['prediction']['shares_to_trade'],\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "template_df = pd.DataFrame(template_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SCENARIO TEMPLATE PREDICTIONS\")\n",
    "print(\"=\" * 100)\n",
    "for idx, row in template_df.iterrows():\n",
    "    print(f\"\\n{idx+1}. {row['Scenario']}\")\n",
    "    print(f\"   {row['Description']}\")\n",
    "    print(f\"   Market: S=${row['Spot']:.0f}, K=${row['Strike']:.0f}, \"\n",
    "          f\"T={row['TTM']*252:.0f}d, Ïƒ={row['Vol']:.1%}, Type={row['Type']}\")\n",
    "    print(f\"   RL Hedge: {row['RL_Hedge']:.4f} | BS Delta: {row['BS_Delta']:.4f} | \"\n",
    "          f\"Deviation: {row['Deviation']:+.4f}\")\n",
    "    print(f\"   Confidence: {row['Confidence']:.1%} | Action: {row['Action']:+.4f} shares\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(template_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, template_df['RL_Hedge'], width, label='RL Agent', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, template_df['BS_Delta'], width, label='Black-Scholes', color='coral')\n",
    "\n",
    "ax.set_xlabel('Scenario')\n",
    "ax.set_ylabel('Hedge Ratio')\n",
    "ax.set_title('RL Agent vs Black-Scholes Delta: Pre-Defined Scenarios')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(template_df['Scenario'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/scenario_templates_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Scenario template analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f715d2",
   "metadata": {},
   "source": [
    "### 5.3 Export Results in Multiple Formats\n",
    "\n",
    "Export predictions for downstream systems and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export batch results in multiple formats\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "export_dir = Path(\"results/exports\")\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 1. CSV (already saved, but let's create a summary version)\n",
    "summary_cols = ['spot_price', 'strike', 'option_type', 'time_to_maturity', 'volatility',\n",
    "                'target_hedge_ratio', 'bs_delta', 'delta_deviation', 'confidence', \n",
    "                'shares_to_trade', 'trade_value', 'scenario_type']\n",
    "results_df[summary_cols].to_csv(f\"{export_dir}/predictions_summary_{timestamp}.csv\", index=False)\n",
    "print(f\"âœ“ CSV exported: {export_dir}/predictions_summary_{timestamp}.csv\")\n",
    "\n",
    "# 2. Excel with multiple sheets\n",
    "try:\n",
    "    with pd.ExcelWriter(f\"{export_dir}/predictions_{timestamp}.xlsx\", engine='openpyxl') as writer:\n",
    "        # Full results\n",
    "        results_df.to_excel(writer, sheet_name='Full_Results', index=False)\n",
    "        \n",
    "        # Summary statistics by scenario\n",
    "        scenario_stats = results_df.groupby('scenario_type').agg({\n",
    "            'target_hedge_ratio': ['mean', 'std', 'min', 'max'],\n",
    "            'confidence': ['mean', 'min'],\n",
    "            'abs_delta_deviation': 'mean',\n",
    "        }).round(4)\n",
    "        scenario_stats.to_excel(writer, sheet_name='Scenario_Stats')\n",
    "        \n",
    "        # High confidence trades only\n",
    "        high_conf = results_df[results_df['confidence'] >= 0.8]\n",
    "        high_conf[summary_cols].to_excel(writer, sheet_name='High_Confidence', index=False)\n",
    "        \n",
    "    print(f\"âœ“ Excel exported: {export_dir}/predictions_{timestamp}.xlsx\")\n",
    "except ImportError:\n",
    "    print(\"âš  Excel export requires openpyxl: pip install openpyxl\")\n",
    "\n",
    "# 3. JSON for API integration\n",
    "json_results = []\n",
    "for idx, row in results_df.iterrows():\n",
    "    json_results.append({\n",
    "        'prediction_id': idx,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'input': {\n",
    "            'spot_price': float(row['spot_price']),\n",
    "            'strike': float(row['strike']),\n",
    "            'time_to_maturity': float(row['time_to_maturity']),\n",
    "            'volatility': float(row['volatility']),\n",
    "            'option_type': row['option_type'],\n",
    "            'current_hedge': float(row['current_hedge']),\n",
    "        },\n",
    "        'prediction': {\n",
    "            'target_hedge_ratio': float(row['target_hedge_ratio']),\n",
    "            'shares_to_trade': float(row['shares_to_trade']),\n",
    "            'trade_value': float(row['trade_value']),\n",
    "            'confidence': float(row['confidence']),\n",
    "        },\n",
    "        'benchmark': {\n",
    "            'black_scholes_delta': float(row['bs_delta']),\n",
    "            'deviation': float(row['delta_deviation']),\n",
    "        },\n",
    "        'metadata': {\n",
    "            'scenario_type': row['scenario_type'],\n",
    "            'moneyness': float(row['moneyness']),\n",
    "        }\n",
    "    })\n",
    "\n",
    "with open(f\"{export_dir}/predictions_{timestamp}.json\", 'w') as f:\n",
    "    json.dump({\n",
    "        'export_time': datetime.now().isoformat(),\n",
    "        'model_type': 'PPO',\n",
    "        'total_predictions': len(json_results),\n",
    "        'predictions': json_results[:10]  # Save first 10 for demo (full export would be large)\n",
    "    }, f, indent=2)\n",
    "print(f\"âœ“ JSON exported: {export_dir}/predictions_{timestamp}.json (sample of 10)\")\n",
    "\n",
    "# 4. Trading instruction format (for execution systems)\n",
    "trading_instructions = []\n",
    "for idx, row in results_df.iterrows():\n",
    "    if row['confidence'] >= 0.75:  # Only high confidence trades\n",
    "        instruction = {\n",
    "            'order_id': f\"RL_{timestamp}_{idx:04d}\",\n",
    "            'security': f\"{row['option_type'].upper()}_{row['strike']:.0f}_{row['time_to_maturity']*252:.0f}D\",\n",
    "            'action': 'BUY' if row['shares_to_trade'] > 0 else 'SELL',\n",
    "            'quantity': abs(float(row['shares_to_trade'])),\n",
    "            'reason': f\"RL_hedge_adjustment\",\n",
    "            'confidence': float(row['confidence']),\n",
    "            'current_delta': float(row['current_hedge']),\n",
    "            'target_delta': float(row['target_hedge_ratio']),\n",
    "        }\n",
    "        trading_instructions.append(instruction)\n",
    "\n",
    "with open(f\"{export_dir}/trading_instructions_{timestamp}.json\", 'w') as f:\n",
    "    json.dump({\n",
    "        'generated_at': datetime.now().isoformat(),\n",
    "        'total_instructions': len(trading_instructions),\n",
    "        'instructions': trading_instructions\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Trading instructions exported: {export_dir}/trading_instructions_{timestamp}.json\")\n",
    "print(f\"\\nExport Summary:\")\n",
    "print(f\"  Total predictions: {len(results_df)}\")\n",
    "print(f\"  High confidence (â‰¥75%): {len(trading_instructions)}\")\n",
    "print(f\"  Export directory: {export_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0f4ff",
   "metadata": {},
   "source": [
    "### 5.4 Batch Inference Summary\n",
    "\n",
    "**What we accomplished in this section:**\n",
    "\n",
    "âœ“ **Diverse Scenarios**: Generated 200 test cases across 5 market regimes\n",
    "- Standard conditions (40%)\n",
    "- Out-of-the-money (20%)\n",
    "- In-the-money (20%)\n",
    "- High volatility (10%)\n",
    "- Near expiration (10%)\n",
    "\n",
    "âœ“ **Benchmark Comparisons**: Calculated Black-Scholes delta for all predictions\n",
    "- Mean absolute deviation from BS\n",
    "- Correlation analysis\n",
    "- Identification of significant deviations\n",
    "\n",
    "âœ“ **Performance Profiling**: Measured inference speed and throughput\n",
    "- Predictions per second\n",
    "- Average latency per prediction\n",
    "- Confidence distribution\n",
    "\n",
    "âœ“ **Scenario Analysis**: Analyzed performance by market regime\n",
    "- Aggregated statistics by scenario type\n",
    "- Visualization of differences\n",
    "- Risk-adjusted metrics\n",
    "\n",
    "âœ“ **Real-World Templates**: Pre-defined scenarios for common situations\n",
    "- Market crash\n",
    "- Bull market\n",
    "- Low volatility\n",
    "- Pre-earnings\n",
    "- Expiration week\n",
    "- Deep OTM protection\n",
    "\n",
    "âœ“ **Multi-Format Export**: Ready for production integration\n",
    "- CSV for spreadsheets\n",
    "- Excel with multiple sheets\n",
    "- JSON for APIs\n",
    "- Trading instructions format\n",
    "\n",
    "**Next**: Advanced visualization and risk management analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d54ac7",
   "metadata": {},
   "source": [
    "## 6. Advanced Visualization & Analysis\n",
    "\n",
    "Comprehensive visualizations showing RL predictions vs Black-Scholes benchmarks across market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df086d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of predictions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. Hedge ratio vs Moneyness (RL and BS)\n",
    "moneyness = results_df['moneyness']\n",
    "axes[0, 0].scatter(moneyness, results_df['target_hedge_ratio'], \n",
    "                   c=results_df['confidence'], cmap='viridis', alpha=0.6, \n",
    "                   label='RL Agent', s=50)\n",
    "axes[0, 0].scatter(moneyness, results_df['bs_delta'], \n",
    "                   alpha=0.3, color='red', marker='x', s=30, label='BS Delta')\n",
    "axes[0, 0].set_xlabel('Moneyness (S/K)')\n",
    "axes[0, 0].set_ylabel('Hedge Ratio')\n",
    "axes[0, 0].set_title('Hedge Ratio vs Moneyness')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "cbar1 = plt.colorbar(axes[0, 0].collections[0], ax=axes[0, 0])\n",
    "cbar1.set_label('Confidence')\n",
    "\n",
    "# 2. Hedge ratio vs Time to Maturity\n",
    "axes[0, 1].scatter(results_df['time_to_maturity'], results_df['target_hedge_ratio'],\n",
    "                   c=results_df['confidence'], cmap='viridis', alpha=0.6, s=50,\n",
    "                   label='RL Agent')\n",
    "axes[0, 1].scatter(results_df['time_to_maturity'], results_df['bs_delta'],\n",
    "                   alpha=0.3, color='red', marker='x', s=30, label='BS Delta')\n",
    "axes[0, 1].set_xlabel('Time to Maturity (years)')\n",
    "axes[0, 1].set_ylabel('Hedge Ratio')\n",
    "axes[0, 1].set_title('Hedge Ratio vs Time to Maturity')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Hedge ratio vs Volatility\n",
    "axes[0, 2].scatter(results_df['volatility'], results_df['target_hedge_ratio'],\n",
    "                   c=results_df['confidence'], cmap='viridis', alpha=0.6, s=50,\n",
    "                   label='RL Agent')\n",
    "axes[0, 2].scatter(results_df['volatility'], results_df['bs_delta'],\n",
    "                   alpha=0.3, color='red', marker='x', s=30, label='BS Delta')\n",
    "axes[0, 2].set_xlabel('Volatility')\n",
    "axes[0, 2].set_ylabel('Hedge Ratio')\n",
    "axes[0, 2].set_title('Hedge Ratio vs Volatility')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. RL vs BS Delta (scatter)\n",
    "axes[1, 0].scatter(results_df['bs_delta'], results_df['target_hedge_ratio'],\n",
    "                   c=results_df['confidence'], cmap='plasma', alpha=0.6, s=50)\n",
    "# Add diagonal line (perfect match)\n",
    "min_val = min(results_df['bs_delta'].min(), results_df['target_hedge_ratio'].min())\n",
    "max_val = max(results_df['bs_delta'].max(), results_df['target_hedge_ratio'].max())\n",
    "axes[1, 0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Match')\n",
    "axes[1, 0].set_xlabel('Black-Scholes Delta')\n",
    "axes[1, 0].set_ylabel('RL Agent Hedge Ratio')\n",
    "axes[1, 0].set_title('RL Agent vs Black-Scholes')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "cbar2 = plt.colorbar(axes[1, 0].collections[0], ax=axes[1, 0])\n",
    "cbar2.set_label('Confidence')\n",
    "\n",
    "# 5. Trade value distribution by option type\n",
    "call_trades = results_df[results_df['option_type'] == 'call']['trade_value']\n",
    "put_trades = results_df[results_df['option_type'] == 'put']['trade_value']\n",
    "axes[1, 1].hist([call_trades, put_trades], bins=30, alpha=0.7, \n",
    "                label=['Calls', 'Puts'], color=['steelblue', 'coral'])\n",
    "axes[1, 1].axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1, 1].set_xlabel('Trade Value ($)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Trade Values by Option Type')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Deviation distribution\n",
    "axes[1, 2].hist(results_df['delta_deviation'], bins=40, alpha=0.7, \n",
    "                edgecolor='black', color='mediumseagreen')\n",
    "axes[1, 2].axvline(0, color='red', linestyle='--', linewidth=2, label='No Deviation')\n",
    "axes[1, 2].axvline(results_df['delta_deviation'].mean(), color='blue', \n",
    "                   linestyle='--', linewidth=2, label=f'Mean: {results_df[\"delta_deviation\"].mean():.4f}')\n",
    "axes[1, 2].set_xlabel('Deviation from BS Delta')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].set_title('Distribution of Deviations from Black-Scholes')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/batch_analysis_enhanced.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Enhanced batch analysis plots saved\")\n",
    "print(f\"\\nðŸ“Š Key Insights:\")\n",
    "print(f\"  Correlation with BS: {results_df['target_hedge_ratio'].corr(results_df['bs_delta']):.3f}\")\n",
    "print(f\"  Mean Deviation: {results_df['delta_deviation'].mean():+.4f}\")\n",
    "print(f\"  Cases where |deviation| > 0.1: {(results_df['abs_delta_deviation'] > 0.1).sum()} ({(results_df['abs_delta_deviation'] > 0.1).mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b61d3",
   "metadata": {},
   "source": [
    "## 7. Generate Batch Report\n",
    "\n",
    "The pipeline can generate comprehensive reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1437d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report\n",
    "report = pipeline.generate_batch_report(\n",
    "    results_df=results_df,\n",
    "    output_path=\"results/batch_inference_report.txt\",\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc0838",
   "metadata": {},
   "source": [
    "## 8. Risk Management: Confidence-Based Filtering\n",
    "\n",
    "In production, you might want to only execute high-confidence predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769adc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by confidence\n",
    "confidence_threshold = 0.8\n",
    "high_confidence = results_df[results_df['confidence'] >= confidence_threshold]\n",
    "low_confidence = results_df[results_df['confidence'] < confidence_threshold]\n",
    "\n",
    "print(f\"Risk Management Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Predictions: {len(results_df)}\")\n",
    "print(f\"High Confidence (â‰¥{confidence_threshold:.0%}): {len(high_confidence)} ({len(high_confidence)/len(results_df):.1%})\")\n",
    "print(f\"Low Confidence (<{confidence_threshold:.0%}): {len(low_confidence)} ({len(low_confidence)/len(results_df):.1%})\")\n",
    "\n",
    "print(f\"\\nHigh Confidence Trades:\")\n",
    "print(f\"  Total Trade Value: ${high_confidence['trade_value'].abs().sum():,.2f}\")\n",
    "print(f\"  Average Hedge Ratio: {high_confidence['target_hedge_ratio'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nLow Confidence Trades (may want to skip):\")\n",
    "print(f\"  Total Trade Value: ${low_confidence['trade_value'].abs().sum():,.2f}\")\n",
    "print(f\"  Average Hedge Ratio: {low_confidence['target_hedge_ratio'].mean():.4f}\")\n",
    "\n",
    "# Visualize confidence distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(results_df['confidence'], bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(confidence_threshold, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Threshold ({confidence_threshold:.0%})')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Confidence Score Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('results/confidence_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8d231",
   "metadata": {},
   "source": [
    "## 9. Inference Speed Benchmark\n",
    "\n",
    "Let's test the inference throughput for production deployment planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark inference speed\n",
    "print(\"Running inference speed benchmark...\")\n",
    "print(\"Testing with 1,000 predictions\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "benchmark_results = pipeline.benchmark_inference_speed(n_samples=1000)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BENCHMARK RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Number of Samples: {benchmark_results['n_samples']:,}\")\n",
    "print(f\"Total Time: {benchmark_results['total_time_seconds']:.2f} seconds\")\n",
    "print(f\"Throughput: {benchmark_results['samples_per_second']:.1f} predictions/second\")\n",
    "print(f\"Latency: {benchmark_results['ms_per_sample']:.2f} ms/prediction\")\n",
    "\n",
    "print(\"\\nðŸ“Š Production Capacity Estimate:\")\n",
    "print(f\"  Per Minute: ~{benchmark_results['samples_per_second']*60:,.0f} predictions\")\n",
    "print(f\"  Per Hour: ~{benchmark_results['samples_per_second']*3600:,.0f} predictions\")\n",
    "print(f\"  Per Day: ~{benchmark_results['samples_per_second']*86400:,.0f} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d9cc2",
   "metadata": {},
   "source": [
    "## 10. Component-Level Testing\n",
    "\n",
    "Let's test each pipeline component independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9819ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DataLoader\n",
    "print(\"Testing DataLoader...\")\n",
    "loader = DataLoader()\n",
    "\n",
    "loaded_data = loader.load_from_csv(\"data/test_scenarios.csv\")\n",
    "print(f\"âœ“ Loaded {len(loaded_data)} rows\")\n",
    "\n",
    "realtime_obs = loader.load_realtime_observation(\n",
    "    spot_price=105, strike=100, time_to_maturity=0.25,\n",
    "    risk_free_rate=0.05, volatility=0.25\n",
    ")\n",
    "print(f\"âœ“ Created real-time observation\")\n",
    "\n",
    "# Test Preprocessor\n",
    "print(\"\\nTesting Preprocessor...\")\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "features = preprocessor.engineer_features(\n",
    "    spot_price=105, strike=100, time_to_maturity=0.25,\n",
    "    risk_free_rate=0.05, volatility=0.25\n",
    ")\n",
    "print(f\"âœ“ Engineered features: shape={features.shape}\")\n",
    "print(f\"  Features: {features}\")\n",
    "\n",
    "# Test PostProcessor\n",
    "print(\"\\nTesting PostProcessor...\")\n",
    "postprocessor = PostProcessor()\n",
    "\n",
    "action = np.array([0.75])\n",
    "processed = postprocessor.process_action(\n",
    "    action=action,\n",
    "    current_hedge=0.5,\n",
    "    spot_price=105.0,\n",
    ")\n",
    "print(f\"âœ“ Processed action:\")\n",
    "print(f\"  Target hedge: {processed['target_hedge_ratio']:.4f}\")\n",
    "print(f\"  Adjustment: {processed['hedge_adjustment']:.4f}\")\n",
    "print(f\"  Shares to trade: {processed['shares_to_trade']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ All components working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb50db",
   "metadata": {},
   "source": [
    "## 11. Production Deployment Patterns\n",
    "\n",
    "Here are common patterns for deploying the inference pipeline in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a45100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Production Deployment Patterns\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "patterns = \"\"\"\n",
    "1. BATCH PROCESSING (Recommended for start)\n",
    "   - Run inference on all positions daily/hourly\n",
    "   - Low latency requirements\n",
    "   - Easy to implement and monitor\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   # Scheduled job (e.g., cron)\n",
    "   pipeline = InferencePipeline(\"models/production.zip\")\n",
    "   results = pipeline.predict_batch(\"data/current_positions.csv\")\n",
    "   results.to_csv(\"data/hedge_recommendations.csv\")\n",
    "   ```\n",
    "\n",
    "2. REST API (For integration with trading systems)\n",
    "   - Real-time inference on demand\n",
    "   - Higher latency requirements\n",
    "   - More complex infrastructure\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   from fastapi import FastAPI\n",
    "   app = FastAPI()\n",
    "   pipeline = InferencePipeline(\"models/production.zip\")\n",
    "   \n",
    "   @app.post(\"/predict\")\n",
    "   def predict(market_data: MarketData):\n",
    "       result = pipeline.predict_single(**market_data.dict())\n",
    "       return result\n",
    "   ```\n",
    "\n",
    "3. STREAMING (For high-frequency trading)\n",
    "   - Continuous inference on market data stream\n",
    "   - Very low latency requirements\n",
    "   - Most complex infrastructure\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   import kafka\n",
    "   consumer = kafka.Consumer('market-data')\n",
    "   producer = kafka.Producer('hedge-signals')\n",
    "   pipeline = InferencePipeline(\"models/production.zip\")\n",
    "   \n",
    "   for message in consumer:\n",
    "       result = pipeline.predict_single(**message.value)\n",
    "       producer.send(result)\n",
    "   ```\n",
    "\n",
    "4. MODEL SERVING (Using dedicated serving infrastructure)\n",
    "   - TensorFlow Serving, TorchServe, or Seldon\n",
    "   - Auto-scaling, monitoring, versioning built-in\n",
    "   - Production-grade reliability\n",
    "\"\"\"\n",
    "\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43970d",
   "metadata": {},
   "source": [
    "## 12. Summary and Best Practices\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **Inference Pipeline Benefits:**\n",
    "   - Consistent preprocessing\n",
    "   - Built-in risk management\n",
    "   - Easy monitoring and logging\n",
    "   - Production-ready\n",
    "\n",
    "2. **Performance:**\n",
    "   - ~100-1000 predictions/second on CPU\n",
    "   - ~1000-10000 predictions/second on GPU\n",
    "   - Latency: 1-10ms per prediction\n",
    "\n",
    "3. **Risk Management:**\n",
    "   - Use confidence scores to filter predictions\n",
    "   - Apply position limits (max_hedge_ratio)\n",
    "   - Monitor prediction quality\n",
    "\n",
    "4. **Deployment:**\n",
    "   - Start with batch processing\n",
    "   - Move to API for real-time needs\n",
    "   - Use model serving for scale\n",
    "\n",
    "5. **Monitoring:**\n",
    "   - Track inference speed\n",
    "   - Monitor prediction distribution\n",
    "   - Alert on anomalies\n",
    "\n",
    "**Production Checklist:**\n",
    "- [ ] Train and validate model thoroughly\n",
    "- [ ] Test on out-of-sample data\n",
    "- [ ] Set appropriate risk limits\n",
    "- [ ] Implement monitoring\n",
    "- [ ] Set up alerting\n",
    "- [ ] Plan for model updates\n",
    "- [ ] Document API/interface\n",
    "- [ ] Load testing\n",
    "\n",
    "**Next Steps:**\n",
    "- Test with real market data\n",
    "- Implement your deployment pattern\n",
    "- Set up monitoring dashboard\n",
    "- Create operational runbook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Derivative_Hedging_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
